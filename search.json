[
  {
    "objectID": "guides/guide-01/index.html",
    "href": "guides/guide-01/index.html",
    "title": "1. Setting up an R environment",
    "section": "",
    "text": "Choosing to work with R locally means that you will install R and an IDE on your local computer. This approach offers the following advantages:\n\nFast and responsive performance\nNo reliance on internet connectivity\nFlexibility to customize your environment\n\nThe main disadvantages of working locally are:\n\nyou will need to install R and an IDE on your local computer,\nmanage your own software environment, and\nmanage your own backups and version control for collaborative projects.\n\nThis can be a challenge for new users, but there are a number of resources available to help you get started and troubleshoot any issues you may encounter.\nTo get started, install R from CRAN. You can download the latest version of R for your operating system here. Once you have installed R, you will need to install an IDE. For complete beginners, I recommend RStudio, a free and open-source IDE for R. RStudio provides a number of features that make it easier to work with R. If you are new to R, but have experience with other programming languages, you may prefer to use a more general-purpose IDE such as VS Code.\n\n\n\nYou can also choose to work with R in the cloud, a remote environment. There are a number of cloud-based options for working with R, including Posit Cloud and Microsoft Azure. These options provide a pre-configured R environment that you can access from any computer with an internet connection.\nPosit Cloud provides an environment where you can create, edit, and run R projects from anywhere with internet access. It offers several advantages:\n\nNo need to install R or RStudio locally\nAccess your projects from any device\nCollaborate with others in real-time\nEasily share your work\n\nSome of the drawbacks of working in the cloud include:\n\nReliance on stable internet connection\nPotential latency and performance issues\nLimited customization options compared to a local setup\n\nTo get started with Posit Cloud, you will need to create an account. You can sign up for a free account here. Once you have created an account, you will see a list of spaces. By default you will have your personal workspace, but you can also join or be invited to other spaces.\nVisit the Guide documentation to learn more about the features of Posit Cloud.\n\n\n\nIf you are new to R, you may want to consider working in the cloud to get started. If you plan to continue to work with R in the future, you will most likely want to install R and an IDE on your local computer or explore using a virtual environment. Virtual environments, such as Docker, provide a way to use a pre-configured computing environment or create your own that you can share with others. Virtual environments are a good option if you want to ensure that everyone in your research group is working with the same computing environment. Pre-configured virtual environments exist for R through the Rocker project and can be used locally or in the cloud.\nUsing Docker with Rocker offers several benefits:\n\nReproducible environments\nSimplified dependency management\nEasy deployment and scaling\n\nThe drawbacks to using Docker with Rocker include:\n\nLearning curve for setting up and managing Docker containers\nIncreased memory and resource requirements\nPotential compatibility issues with certain packages or libraries\n\nTo start using Docker with Rocker, follow these steps:\n\nInstall Docker on your local machine\nPull the desired Rocker image from Docker Hub\ndocker pull rocker/rstudio\nRun a container using the pulled image\ndocker run -d -p 8787:8787 -e PASSWORD=your_password --name rstudio_container rocker/rstudio\nAccess RStudio in your browser at http://localhost:8787 and log in with username rstudio and the password you set"
  },
  {
    "objectID": "guides/guide-01/index.html#environment-setups",
    "href": "guides/guide-01/index.html#environment-setups",
    "title": "1. Setting up an R environment",
    "section": "",
    "text": "Choosing to work with R locally means that you will install R and an IDE on your local computer. This approach offers the following advantages:\n\nFast and responsive performance\nNo reliance on internet connectivity\nFlexibility to customize your environment\n\nThe main disadvantages of working locally are:\n\nyou will need to install R and an IDE on your local computer,\nmanage your own software environment, and\nmanage your own backups and version control for collaborative projects.\n\nThis can be a challenge for new users, but there are a number of resources available to help you get started and troubleshoot any issues you may encounter.\nTo get started, install R from CRAN. You can download the latest version of R for your operating system here. Once you have installed R, you will need to install an IDE. For complete beginners, I recommend RStudio, a free and open-source IDE for R. RStudio provides a number of features that make it easier to work with R. If you are new to R, but have experience with other programming languages, you may prefer to use a more general-purpose IDE such as VS Code.\n\n\n\nYou can also choose to work with R in the cloud, a remote environment. There are a number of cloud-based options for working with R, including Posit Cloud and Microsoft Azure. These options provide a pre-configured R environment that you can access from any computer with an internet connection.\nPosit Cloud provides an environment where you can create, edit, and run R projects from anywhere with internet access. It offers several advantages:\n\nNo need to install R or RStudio locally\nAccess your projects from any device\nCollaborate with others in real-time\nEasily share your work\n\nSome of the drawbacks of working in the cloud include:\n\nReliance on stable internet connection\nPotential latency and performance issues\nLimited customization options compared to a local setup\n\nTo get started with Posit Cloud, you will need to create an account. You can sign up for a free account here. Once you have created an account, you will see a list of spaces. By default you will have your personal workspace, but you can also join or be invited to other spaces.\nVisit the Guide documentation to learn more about the features of Posit Cloud.\n\n\n\nIf you are new to R, you may want to consider working in the cloud to get started. If you plan to continue to work with R in the future, you will most likely want to install R and an IDE on your local computer or explore using a virtual environment. Virtual environments, such as Docker, provide a way to use a pre-configured computing environment or create your own that you can share with others. Virtual environments are a good option if you want to ensure that everyone in your research group is working with the same computing environment. Pre-configured virtual environments exist for R through the Rocker project and can be used locally or in the cloud.\nUsing Docker with Rocker offers several benefits:\n\nReproducible environments\nSimplified dependency management\nEasy deployment and scaling\n\nThe drawbacks to using Docker with Rocker include:\n\nLearning curve for setting up and managing Docker containers\nIncreased memory and resource requirements\nPotential compatibility issues with certain packages or libraries\n\nTo start using Docker with Rocker, follow these steps:\n\nInstall Docker on your local machine\nPull the desired Rocker image from Docker Hub\ndocker pull rocker/rstudio\nRun a container using the pulled image\ndocker run -d -p 8787:8787 -e PASSWORD=your_password --name rstudio_container rocker/rstudio\nAccess RStudio in your browser at http://localhost:8787 and log in with username rstudio and the password you set"
  },
  {
    "objectID": "guides/guide-01/index.html#summary",
    "href": "guides/guide-01/index.html#summary",
    "title": "1. Setting up an R environment",
    "section": "Summary",
    "text": "Summary\nIn this guide, we have discussed strategies for working with R. All three options offer unique advantages. In Table 1, we summarize some of the characteristics, benefits, and drawbacks of each option.\n\n\n\nTable 1: Comparison of different environments for working with R and RStudio\n\n\n\n\n\n\n\n\n\n\n\nEnvironment\nCharacteristics\nBenefits\nDrawbacks\n\n\n\n\nLocal (Computer)\n- R/RStudio installed locally- Project files stored on local machine- Accessible without internet connection- Full control over software version and environment\n- Fast and responsive performance- No reliance on internet connectivity- Ability to work offline- Complete control over software version and environment\n- Limited collaboration options- Difficulty in sharing projects with others- Potential compatibility issues with different operating systems\n\n\nRemote (Cloud)\n- R/RStudio accessed via web browser- Project files stored on cloud server- Accessible from any device with internet connection- Easy collaboration with others- Automatic backups and version control\n- No need for local installation or setup- Easy access from anywhere- Seamless collaboration with teammates- Backup and version control provided by the cloud service\n- Reliance on stable internet connection- Potential latency and performance issues- Limited customization options compared to a local setup\n\n\nVirtual (Docker)\n- R/RStudio environment encapsulated in a Docker container- Project files stored locally or on the cloud- Consistent environment across different machines\n- Reproducible and portable environment- Easy setup and sharing of the container- Flexibility to run on different operating systems- Isolation from host system dependencies\n- Learning curve for setting up and managing Docker containers- Increased memory and resource requirements- Potential compatibility issues with certain packages or libraries\n\n\n\n\n\n\nGive them a try and see which one works best for your needs! Remember, you can always switch between different environments as your needs change."
  },
  {
    "objectID": "guides/guide-01/index.html#references",
    "href": "guides/guide-01/index.html#references",
    "title": "1. Setting up an R environment",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "guides/guide-04/index.html",
    "href": "guides/guide-04/index.html",
    "title": "Guide 04",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "guides/guide-02/index.html",
    "href": "guides/guide-02/index.html",
    "title": "Guide 02",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "recipes/recipe-11/index.html",
    "href": "recipes/recipe-11/index.html",
    "title": "Recipe 11",
    "section": "",
    "text": "Hello.\n\n\n\n\n\n\n Dive deeper\nWhen creating a reproducible computing environment, it will be necessary to include system dependencies to ensure that the project is reproducible. The pak package provides a way to determine the dependencies for a package or set of packages on a given operating system (platform).\npak::pkg_sysreqs(pkg = \"knitr\", sysreqs = \"ubuntu\")\n── Install scripts ── Ubuntu NA\napt-get -y update\napt-get -y install pandoc\n\n── Packages/ system dependencies\nknitr – pandoc\nThese can be added to the computational setup script for the project."
  },
  {
    "objectID": "recipes/recipe-04/index.html",
    "href": "recipes/recipe-04/index.html",
    "title": "Recipe 04",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "recipes/recipe-02/index.html",
    "href": "recipes/recipe-02/index.html",
    "title": "2. Reading, inspecting, and writing datasets",
    "section": "",
    "text": "Skills\n\nLoading packages into an R session\nReading datasets into R with read_*() functions\nInspecting datasets with dplyr functions\nWriting datasets to a file with write_*() functions"
  },
  {
    "objectID": "recipes/recipe-02/index.html#concepts-and-strategies",
    "href": "recipes/recipe-02/index.html#concepts-and-strategies",
    "title": "2. Reading, inspecting, and writing datasets",
    "section": "Concepts and strategies",
    "text": "Concepts and strategies\n\nQuarto documents and code blocks\nAsk you will remember from Recipes 0 and 1, Quarto documents can combine prose and code. The prose is written in Markdown and the code is written in R1. The code is contained in code blocks, which are opened by three backticks (`), the name of the programming language, r, in curly braces {r} and three backticks (`) to close the block. For example, the following minimal Quarto document contains an R code block:\n---\ntitle: My Quarto Document\nformat: pdf\n---\n\n# Goals\n\nThis script ...\n\n```{r}\n#| label: code-block-name\n\n# R code goes here\n```\n\nAs you can see in the code block, the ...\nCode blocks have various options that can be added by using key-value pairs that are prefixed with #|. Some common key-value pairs we will use in this Recipe are:\n\nlabel: A unique name for the code block. This is used to reference the code block.\necho: A boolean value (true or false) that determines whether the code is displayed in the output document.\ninclude: A boolean value (true or false) that determines whether the output of the code is displayed in the output document.\nmessage: A boolean value (true or false) that determines whether the messages from the code are displayed in the output document.\n\n\n\nSetting up the environment\nBefore we can read, inspect, and write data, we need to load the packages that contain the functions we will use. We will use the readr package to read datasets into R and write datasets to disk and the dplyr package to inspect and transform (subset) the data.\nThere are a few ways to load packages into an R session. The most common way is to use the library() function. The library() function loads a package into the R session and stops the script if the package is not available on the current computing environment.\nFor example, the following code block loads the readr and dplyr packages into the R session:\n\n```{r}\n#| label: load-packages\n\n# Load packages\nlibrary(readr) # for reading and writing data\nlibrary(dplyr) # for inspecting and transforming data\n```\n\nThis code block assumes that the readr and dplyr packages are installed on the current computing environment. If the packages are not installed, the code block will stop and display an error message, such as:\nError in library(readr) : there is no package called ‘readr’\nThis error can be addressed by installing the missing package with install.packages(\"readr\") and then re-running the code block. This is not ideal for reproducibility, however, because the code block will stop if the package is not installed. We will consider a more reproducible approach later in the course.\n\n\n\n\n\n\n Dive deeper\nIf you interested in learning about safeguarding package loading in a reproducible way, see the renv package. The renv package is a project-oriented workflow to create a reproducible environment for R projects. For more information, see the renv documentation.\n\n\n\n\n\nUnderstanding the data\nNow that we have our environment set up, we can read the dataset into R. But before we do, we should make sure that we understand the data by looking at the data documentation.\nThe dataset that we will read into our R session based on the Brown Corpus (Francis and Kuçera 1961). I’ve created a data origin file that contains the data documentation for the Brown Corpus, as we can see in Table 1.\n\n# Read and display the data origin file\n\nread_csv(file = \"data/original/brown_passives_do.csv\") |&gt;\n  kable() |&gt;\n  kable_styling() |&gt;\n  column_spec(1, width = \"15em\")\n\n\n\nTable 1: Data origin file for the Brown Corpus.\n\n\n\n\n\n\n\nattribute\ndescription\n\n\n\n\nResource name\nBrown Corpus\n\n\nData source\nhttp://korpus.uib.no/icame/brown/bcm.html\n\n\nData sampling frame\nEdited American English prose from various genres, published in the United States during the calendar year 1961.\n\n\nData collection date(s)\nOriginally published in 1964, revised in 1971 and 1979.\n\n\nData format\nMultiple formats including Form A (original), Form B (stripped version), Form C (tagged version), Bergen Forms I and II, and Brown MARC Form.\n\n\nData schema\n500 samples of approximately 2000 words each, covering a wide range of genres and styles. Includes coding for major and minor headings, special types (italics, bold, etc.), abbreviations, symbols, and other textual features.\n\n\nLicense\nUse restricted for scholarly research in linguistics, stylistics, and other disciplines. Specific copyright restrictions detailed in the manual.\n\n\nAttribution\nW. Nelson Francis and Henry Kucera, Brown University, 1964, revised 1971 and 1979.\n\n\n\n\n\n\n\n\n\n\n\nThis data origin file provides an overview of the original data source. In this case, the dataset we will read into R is a subset of the Brown Corpus which is an aggregate of the use of passive voice. This dataset was developed by the authors of the corpora package (Evert 2023). I’ve exported the dataset to a CSV file, which we will read into R.\nThe data dictionary which describes the dataset we will read appears in Table 2.\n# Read and display the data documentation file\nread_csv(file = \"../data/derived/brown_passives_curated_dd.csv\") |&gt;\n  kable() |&gt;\n  kable_styling()\n\n\n\n\nTable 2: Data dictionary file for the Brown Corpus.\n\n\n\n\n\n\n\nvariable\nname\nvariable_type\ndescription\n\n\n\n\ncat\nCategory\ncategorical\nGenre categories represented by letters\n\n\npassive\nPassive\nnumeric\nNumber of passive verb phrases in the genre\n\n\nn_w\nNumber of words\nnumeric\nNumber of words in the genre\n\n\nn_s\nNumber of sentences\nnumeric\nNumber of sentences in the genre\n\n\nname\nGenre\ncategorical\nGenre name\n\n\n\n\n\n\n\n\n\n\n\nWith this information, we are now in a position to read and inspect the dataset.\n\n\nReading datasets into R with readr\nWe’ve now prepared our Quarto document by loading the packages we will use and and we have reviewed the dataset documentation so that we understand the dataset we will read into R. We are now ready to read the dataset into R.\nR provides a number of functions to read data of many types in R. We will explore many types of data and datasets in this course. For now, we will focus on reading rectangular data into R. Rectangular data is data that is organized in rows and columns, such as a spreadsheet.\nOne of the most common file formats for rectangular data is the comma-separated values (CSV) file. CSV files are text files in which lines represent rows and commas separate columns of data. For example, the sample CSV file snippet below contains three rows and three columns of data:\n\"word\",\"frequency\",\"part_of_speech\"\n\"the\",69971,\"article\"\n\"of\",36412,\"preposition\"\n\"and\",28853,\"conjunction\"\nA CSV file is a type of delimited file, which means that the data is separated by a delimiter. In the case of a CSV file, the delimiter is a comma. Other types of delimited files use different delimiters, such as tab-separated values (TSV) files which use a tab character as the delimiter, or even a pipe (|) or semicolon (;).\nThe readr package provides functions to read rectangular dataset into R. The read_csv() function reads CSV files, the read_tsv() function reads TSV files, and the read_delim() function reads other types of delimited files.\nLet’s use the read_csv() function to read the brown_passives_curated.csv file into R. To do this we will use the file = argument to specify the path to the file. Now, the file “path” is the location of the file on the computer. We can specify this path in two ways:\n\nRelative path: The relative path is the path to the file relative to the current working directory. The current working directory is the directory in which the R session is running.\nAbsolute path: The absolute path is the path to the file from the root directory of the computer.\n\nFor most purpose, the relative path is the better option because it is more portable. For example, if you share your code with someone else, they may have a different absolute path to the file. However, they will likely have the same relative path to the file.\nLet’s say that the directory structure of our project is as follows:\nproject/\n├── data/\n│   ├── original/\n│   │   └── brown_passives_do.csv\n│   └── derived/\n│       └── brown_passives_curated.csv\n└── code/\n    └── reading-inspecting-writing.qmd\nIn this case, the relative path from reading-inspecting-writing.qmd to the brown_passives_curated.csv file is ../data/derived/brown_passives_curated.csv. The .. means “go up one directory” and the rest of the path is the path to the file from the project/ directory.\nWith this in mind, we can read the brown_passives_curated.csv file into R with the following code block:\n#| label: read-dataset-brown-passives-curated\n\n# Read the dataset\nbrown_passives_df &lt;-\n  read_csv(file = \"../data/derived/brown_passives_curated.csv\")\nRunning the above code chunk in our Quarto document will read the dataset into R and assign it to the brown_passives_df variable. It will also show the code used to read the dataset into R. Furthermore, so functions will display messages in the output. For example, the read_csv() function will display a message that various parsing options were used to read the dataset into R.\nThis information can be helpful in an interactive session, as read_csv() tells us the dimensions of the dataset and the data types of each column. But this output is not necessary, and is unnecessarily verbose in a reproducible document.\nWe can hide any messages produced by a function by using the message = false key-value pair in the code block. For example, the following code block will read the dataset into R and assign it to the brown_passives_df variable without displaying any messages:\n#| label: read-dataset-brown-passives-curated\n#| message: false\n\n# Read the dataset\nbrown_passives_df &lt;-\n  read_csv(file = \"../data/derived/brown_passives_curated.csv\")\nNo messages are displayed in the document output.\n\n\nInspecting datasets with dplyr\nThe objective of this section is to demonstrate how to inspect and transform (subset) datasets using the dplyr package. We will use the dplyr package to inspect the dataset we read into R in the previous section.\nReading a CSV file into R will create a data frame object. Thus, I assigned the result to brown_passives_df. The df suffix is a common naming convention for rectangular data frames. It is good practice to use a consistent naming convention for objects in your code. This makes it easier to understand the code and to avoid errors.\nLet’s do get an overview of the dataset by using the glimpse() function from the dplyr package. The glimpse() function displays the dimensions of the data frame and the data types of each column.\n\n# Preview\nglimpse(brown_passives_df)\n\n&gt; Rows: 15\n&gt; Columns: 5\n&gt; $ cat     &lt;chr&gt; \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \"M\", \"N…\n&gt; $ passive &lt;dbl&gt; 892, 543, 283, 351, 853, 1034, 1460, 837, 2423, 352, 265, 104,…\n&gt; $ n_w     &lt;dbl&gt; 101196, 61535, 40749, 39029, 82010, 110363, 173017, 69446, 181…\n&gt; $ n_s     &lt;dbl&gt; 3684, 2399, 1459, 1372, 3286, 4387, 6537, 2012, 6311, 3983, 36…\n&gt; $ name    &lt;chr&gt; \"press reportage\", \"press editorial\", \"press reviews\", \"religi…\n\n\nIf we want a more, tabular-like view of the data, we can simply print the dataset frame to the console. It’s worth mentioning, that all readr functions return tibbles, so we gain the benefits of tibbles when we read dataset into R with readr functions, one of which is that we do not have to worry that printing a data frame to the console, or our document, will print all of the data.\n\n# Print the data frame\nbrown_passives_df\n\n&gt; # A tibble: 15 × 5\n&gt;    cat   passive    n_w   n_s name            \n&gt;    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           \n&gt;  1 A         892 101196  3684 press reportage \n&gt;  2 B         543  61535  2399 press editorial \n&gt;  3 C         283  40749  1459 press reviews   \n&gt;  4 D         351  39029  1372 religion        \n&gt;  5 E         853  82010  3286 skills / hobbies\n&gt;  6 F        1034 110363  4387 popular lore    \n&gt;  7 G        1460 173017  6537 belles lettres  \n&gt;  8 H         837  69446  2012 miscellaneous   \n&gt;  9 J        2423 181426  6311 learned         \n&gt; 10 K         352  68599  3983 general fiction \n&gt; 11 L         265  57624  3673 detective       \n&gt; 12 M         104  14433   873 science fiction \n&gt; 13 N         290  69909  4438 adventure       \n&gt; 14 P         290  70476  4187 romance         \n&gt; 15 R         146  21757   975 humour\n\n\nBy default, printing tibbles will return the first 10 rows and all columns, unless the columns are too numerous to display width-wise.\ndplyr also provides a set of slice_*() functions which allow us to display the data in a tabular fashion, with some additional options. There are three slice_*() functions we will cover here:\n\nslice_head(): Select the first n rows of the data frame.\nslice_tail(): Select the last n rows of the data frame.\nslice_sample(): Select a random sample of n rows from the data frame.\n\nFor example, the following code block will select the first 5 rows of the data frame:\n\n# Select the first 5 rows\nslice_head(brown_passives_df, n = 5)\n\n&gt; # A tibble: 5 × 5\n&gt;   cat   passive    n_w   n_s name            \n&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           \n&gt; 1 A         892 101196  3684 press reportage \n&gt; 2 B         543  61535  2399 press editorial \n&gt; 3 C         283  40749  1459 press reviews   \n&gt; 4 D         351  39029  1372 religion        \n&gt; 5 E         853  82010  3286 skills / hobbies\n\n\nWe can also select the last 5 rows of the data frame with the slice_tail() function:\n\n# Select the last 5 rows\nslice_tail(brown_passives_df, n = 5)\n\n&gt; # A tibble: 5 × 5\n&gt;   cat   passive   n_w   n_s name           \n&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          \n&gt; 1 L         265 57624  3673 detective      \n&gt; 2 M         104 14433   873 science fiction\n&gt; 3 N         290 69909  4438 adventure      \n&gt; 4 P         290 70476  4187 romance        \n&gt; 5 R         146 21757   975 humour\n\n\nFinally, we can select a random sample of 5 rows from the data frame with the slice_sample() function:\n\n# Select a random sample of 5 rows\nslice_sample(brown_passives_df, n = 5)\n\n&gt; # A tibble: 5 × 5\n&gt;   cat   passive    n_w   n_s name           \n&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          \n&gt; 1 J        2423 181426  6311 learned        \n&gt; 2 N         290  69909  4438 adventure      \n&gt; 3 L         265  57624  3673 detective      \n&gt; 4 C         283  40749  1459 press reviews  \n&gt; 5 K         352  68599  3983 general fiction\n\n\nThese functions can be helpful to get a sense of the dataset in different ways. In combination with arrange() function, we can also sort the data frame by a column or columns and then select the first or last rows.\nFor example, the following code block will sort the data frame by the passive column in ascending order and then select the first 5 rows:\n\n# Sort by the `passive` column and select the first 5 rows\nslice_head(arrange(brown_passives_df, passive), n = 5)\n\n&gt; # A tibble: 5 × 5\n&gt;   cat   passive   n_w   n_s name           \n&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          \n&gt; 1 M         104 14433   873 science fiction\n&gt; 2 R         146 21757   975 humour         \n&gt; 3 L         265 57624  3673 detective      \n&gt; 4 C         283 40749  1459 press reviews  \n&gt; 5 N         290 69909  4438 adventure\n\n\nIf we want to sort be descending order, we can surround the column name with desc(), arrange(desc(passive)).\nNow, the previous code block does what we want, but it is not very readable. Enter the pipe operator. The pipe operator |&gt; is an operator which allows us to chain the output of one function to the input of another function. This allows us to write more readable code.\n\nbrown_passives_df |&gt;\n  arrange(passive) |&gt;\n  slice_head(n = 5)\n\n&gt; # A tibble: 5 × 5\n&gt;   cat   passive   n_w   n_s name           \n&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;          \n&gt; 1 M         104 14433   873 science fiction\n&gt; 2 R         146 21757   975 humour         \n&gt; 3 L         265 57624  3673 detective      \n&gt; 4 C         283 40749  1459 press reviews  \n&gt; 5 N         290 69909  4438 adventure\n\n\nThe result is the same but the code makes more sense. We can read the code from left to right, top to bottom, which is the order in which the functions are executed.\n\n\n\n\n\n\n Dive deeper\nThe native R pipe |&gt; was introduced in R 4.1.0. If you are using an earlier version of R, you can use the magrittr package to load the pipe operator %&gt;%.\nThere are certain advantages to using the magrittr pipe operator, including the ability to use the pipe operator to pass arguments to functions with placeholders. For more information, see the magrittr documentation.\n\n\n\nIn addition to being more legible, using the pipe with each function on its own line allows us to add comments to each line of code. For example, the following code block is the same as the previous code block, but with comments added.\n\n# Sort by the passive column and select the first 5 rows\nbrown_passives_df |&gt;\n  arrange(passive) |&gt;\n  slice_head(n = 5)\n\nIt is a good practice to add comments when writing code, as long as it makes the code more readable and easier to understand for others and for your future self! If the comments are too verbose, and only repeat what the code is ‘saying’, then don’t include them.\n\n\nSubsetting datasets with dplyr\nNow that we have a sense of the data, we can subset the dataset to create a variations of our original data frame. We can subset the data frame by selecting columns and/ or rows.\nIn the R lesson “Packages and Functions”, we saw that base R provides the bracket ([]) operator to subset data frames. The dplyr package provides functions to subset data frames which can be more readable and easier to use.\nLet’s first look a selecting columns. The select() function allows us to select columns by name. For example, the following code block will select the passive and n_w columns from the data frame:\n\n# Select the `passive` and `n_w` columns\nselect(brown_passives_df, passive, n_w)\n\n&gt; # A tibble: 15 × 2\n&gt;    passive    n_w\n&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n&gt;  1     892 101196\n&gt;  2     543  61535\n&gt;  3     283  40749\n&gt;  4     351  39029\n&gt;  5     853  82010\n&gt;  6    1034 110363\n&gt;  7    1460 173017\n&gt;  8     837  69446\n&gt;  9    2423 181426\n&gt; 10     352  68599\n&gt; 11     265  57624\n&gt; 12     104  14433\n&gt; 13     290  69909\n&gt; 14     290  70476\n&gt; 15     146  21757\n\n\nBeyond selecting columns, we can also reorder columns and rename columns. For example, the following code block will select the passive and n_w columns, rename the n_w column to num_words, and reorder the columns so that num_words is the first column:\n\n# Select rename and reorder columns\nbrown_passives_df |&gt;\n  select(num_words = n_w, passive)\n\n&gt; # A tibble: 15 × 2\n&gt;    num_words passive\n&gt;        &lt;dbl&gt;   &lt;dbl&gt;\n&gt;  1    101196     892\n&gt;  2     61535     543\n&gt;  3     40749     283\n&gt;  4     39029     351\n&gt;  5     82010     853\n&gt;  6    110363    1034\n&gt;  7    173017    1460\n&gt;  8     69446     837\n&gt;  9    181426    2423\n&gt; 10     68599     352\n&gt; 11     57624     265\n&gt; 12     14433     104\n&gt; 13     69909     290\n&gt; 14     70476     290\n&gt; 15     21757     146\n\n\n\n\n\n\n\n\n Dive deeper\nselect() also provides a number of helper functions to select columns. For example, we can use the starts_with() function inside the select() call to select columns that start with a certain string. Or we can select columns by their vector type by using where(is.character).\nFor more information, see the select() documentation or use the ?select command in the R console.\n\n\n\nBy selecting some columns and not others, we have effectively dropped the columns we did not select. If it is more effective to drop columns by name, we can use the select() function with the - operator. For example, the following code block will drop the cat column from the data frame:\n\n# Drop the `n_w` column\nbrown_passives_df |&gt;\n  select(-cat)\n\n&gt; # A tibble: 15 × 4\n&gt;    passive    n_w   n_s name            \n&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           \n&gt;  1     892 101196  3684 press reportage \n&gt;  2     543  61535  2399 press editorial \n&gt;  3     283  40749  1459 press reviews   \n&gt;  4     351  39029  1372 religion        \n&gt;  5     853  82010  3286 skills / hobbies\n&gt;  6    1034 110363  4387 popular lore    \n&gt;  7    1460 173017  6537 belles lettres  \n&gt;  8     837  69446  2012 miscellaneous   \n&gt;  9    2423 181426  6311 learned         \n&gt; 10     352  68599  3983 general fiction \n&gt; 11     265  57624  3673 detective       \n&gt; 12     104  14433   873 science fiction \n&gt; 13     290  69909  4438 adventure       \n&gt; 14     290  70476  4187 romance         \n&gt; 15     146  21757   975 humour\n\n\nLet’s now turn our attention to subsetting rows. The filter() function allows us to select rows by a logical condition. For example, the following code block will select rows where the values of the passive column are less than &lt; 1,000:\n\n# Select rows where `passive` is less than 1,000\nbrown_passives_df |&gt;\n  filter(passive &lt; 1000)\n\n&gt; # A tibble: 12 × 5\n&gt;    cat   passive    n_w   n_s name            \n&gt;    &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;           \n&gt;  1 A         892 101196  3684 press reportage \n&gt;  2 B         543  61535  2399 press editorial \n&gt;  3 C         283  40749  1459 press reviews   \n&gt;  4 D         351  39029  1372 religion        \n&gt;  5 E         853  82010  3286 skills / hobbies\n&gt;  6 H         837  69446  2012 miscellaneous   \n&gt;  7 K         352  68599  3983 general fiction \n&gt;  8 L         265  57624  3673 detective       \n&gt;  9 M         104  14433   873 science fiction \n&gt; 10 N         290  69909  4438 adventure       \n&gt; 11 P         290  70476  4187 romance         \n&gt; 12 R         146  21757   975 humour\n\n\nWe can also use the filter() function to select rows by a character string. For example, the following code block will select rows where the values of the name column are equal to religion:\n\n# Select rows where `name` is equal to `religion`\nbrown_passives_df |&gt;\n  filter(name == \"religion\")\n\n&gt; # A tibble: 1 × 5\n&gt;   cat   passive   n_w   n_s name    \n&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n&gt; 1 D         351 39029  1372 religion\n\n\nThe inequality operator != can be used for character strings as well. To include multiple values, we can use the %in% operator. In this case we can pass a vector of values to the filter() function. For example, the following code block will select rows where the values of the name column are equal to religion or learned:\n\n# Select multiple values\nbrown_passives_df |&gt;\n  filter(name %in% c(\"religion\", \"learned\", \"detective\"))\n\n&gt; # A tibble: 3 × 5\n&gt;   cat   passive    n_w   n_s name     \n&gt;   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    \n&gt; 1 D         351  39029  1372 religion \n&gt; 2 J        2423 181426  6311 learned  \n&gt; 3 L         265  57624  3673 detective\n\n\n\n\n\n\n\n\n Dive deeper\nFor more sophisticated subsetting, we can use the str_detect() function from the stringr package to select rows where the values of the name column contain a certain string. This approach will be enhanced later in the course when we learn about regular expressions.\n\n\n\n\n\nWriting datasets to a file with readr\nFinally, we can write data, including data frames, to a file with the write_*() functions from the readr package. The write_*() functions include:\n\nwrite_csv(): Write a data frame to a CSV file.\nwrite_tsv(): Write a data frame to a TSV file.\nwrite_delim(): Write a data frame to a delimited file with the specified delimiter (|, ;, etc).\n\nTo create a distinct data frame from the one we read into R, let’s subset our brown_passives_df data frame by columns and rows to create a new data frame that contains only the passive, n_w, and name columns and only the rows where the values of the passive column are greater than &gt; 1,000 and assign it to the brown_passives_subset_df.\n\n# Subset the data frame\nbrown_passives_subset_df &lt;-\n  brown_passives_df |&gt;\n  select(passive, n_w, name) |&gt;\n  filter(passive &gt; 1000)\n\nNow the following code block will write the brown_passives_subset_df data frame to a CSV file given the specified file path:\n\n# Write the data frame to a CSV file\nwrite_csv(\n  x = brown_passives_subset_df,\n  file = \"../data/derived/brown_passives_subset.csv\"\n)\n\nGiven the example directory structure we saw earlier, our new file appears in the data/derived/ directory.\nproject/\n├── data/\n│   ├── original/\n│   │   └── brown_passives_do.csv\n│   └── derived/\n│       ├── brown_passives_curated.csv\n│       ├── brown_passives_curated_dd.csv\n│       └── brown_passives_subset.csv\n└── code/\n    └── reading-inspecting-writing.qmd\nThere is much more to learn about reading, inspecting, and writing datasets in R. We will introduce more functions and techniques in the coming lessons. For now, we have learned how to read, inspect, and write datasets using R functions and Quarto code blocks!"
  },
  {
    "objectID": "recipes/recipe-02/index.html#check-your-understanding",
    "href": "recipes/recipe-02/index.html#check-your-understanding",
    "title": "2. Reading, inspecting, and writing datasets",
    "section": "Check your understanding",
    "text": "Check your understanding\n\nTRUEFALSE The readr package provides functions to read rectangular data into R.\nThe echomessageinclude option in a code block determines whether the code is displayed in the output document.\nTRUEFALSE The dplyr package provides functions to create data dictionaries.\nread_csv()read_tsv()read_delim() is used to read tab-separated values (TSV) files.\nWhich function is in dplyr is used to select columns by name? select()filter()slice_head()\nTRUEFALSE The R pipe operator |&gt; allows us to chain the output of one function to the input of another function."
  },
  {
    "objectID": "recipes/recipe-02/index.html#lab-preparation",
    "href": "recipes/recipe-02/index.html#lab-preparation",
    "title": "2. Reading, inspecting, and writing datasets",
    "section": "Lab preparation",
    "text": "Lab preparation\nIn Lab 2 you will have the opportunity to apply the skills you learned in this Recipe to create a Quarto document that reads, inspects, and writes data.\nIn addition to the knowledge and skills you have developed in Labs 0 and 1, to complete Lab 2, you will need to be able to:\n\nCreate code blocks in a Quarto document\nUnderstand the purpose of the label, echo, message, and include options in a code block\nLoad packages into an R session with library()\nUnderstand how to read and create file relative file paths\nRead datasets into R with the read_csv() function\nInspect data frames with dplyr functions such as glimpse(), slice_head(), slice_tail(), slice_sample(), and arrange().\nUse the |&gt; pipe operator to chain functions together.\nSubset data frames with dplyr functions such as select() and filter().\nWrite data frames to a file with the write_csv() function."
  },
  {
    "objectID": "recipes/recipe-02/index.html#footnotes",
    "href": "recipes/recipe-02/index.html#footnotes",
    "title": "2. Reading, inspecting, and writing datasets",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n Code block can be written in other programming languages as well such as Python, Bash, etc.↩︎"
  },
  {
    "objectID": "recipes/index.html",
    "href": "recipes/index.html",
    "title": "Recipes",
    "section": "",
    "text": "0. Literate Programming\n\n\nAn introduction to Quarto\n\n\nIn this recipe, we will introduce the concept of Literate Programming and describe how to implement this concept through Quarto. I will provide a demonstration of some of the features of Quarto and describe the main structural characteristics of a Quarto document to help you get off and running writing your own documents that combine code and prose. \n\n\n\n\n\n8 min\n\n\n1,449 words\n\n\n\n\n\n\n\n\n\n\n\n\n1. Academic writing with Quarto\n\n\nKey Quarto features for academic writing\n\n\nThe implementation of literate programming we are using in this course is Quarto with R. As we have seen in previously, Quarto provides the ability to combine prose and code in a single document. This is a powerful strategy for creating reproducible documents that can be easily updated and shared. \n\n\n\n\n\n12 min\n\n\n2,302 words\n\n\n\n\n\n\n\n\n\n\n\n\n2. Reading, inspecting, and writing datasets\n\n\nBasics of working with datasets in R\n\n\nThis Recipe guides you through the process of reading, inspecting, and writing datasets using R packages and functions in a Quarto environment. You’ll learn how to effectively combine code and narrative to create a reproducible document that can be shared with others. \n\n\n\n\n\n17 min\n\n\n3,221 words\n\n\n\n\n\n\n\n\n\n\n\n\n3. Descriptive assessment of datasets\n\n\n\n\n\nIn this Recipe we will explore appropriate methods for summarizing variables in datasets given the number and informational values of the variable(s). We will build on our understanding of how to summarize data using statistics, tables, and plots. \n\n\n\n\n\n17 min\n\n\n3,290 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 04\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 05\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 06\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 07\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 08\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 09\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 10\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n1 words\n\n\n\n\n\n\n\n\n\n\n\n\nRecipe 11\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n82 words\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "recipes/recipe-00/index.html",
    "href": "recipes/recipe-00/index.html",
    "title": "0. Literate Programming",
    "section": "",
    "text": "Skills\n\nIdentify the main components of a Quarto document\nCreate and render a Quarto document\nModify front-matter and prose sections"
  },
  {
    "objectID": "recipes/recipe-00/index.html#concepts-and-strategies",
    "href": "recipes/recipe-00/index.html#concepts-and-strategies",
    "title": "0. Literate Programming",
    "section": "Concepts and strategies",
    "text": "Concepts and strategies\n\nLiterate Programming\nFirst introduced by Donald Knuth (1984), the aim of Literate Programming is to be able to combine computer code and text prose in one document. This allows an analyst to run code, view the output of the code, view the code itself, and provide prose description all in one document. In this way, a literate programming document allows for presenting your analysis in a way that performs the computing steps desired and presents it in an easily readable format. Literate programming is now a key component of creating and sharing reproducible research (Gandrud 2015).\n\n\nQuarto\nQuarto is a specific implementation of the literate programming paradigm. In Figure 1 we see an example of Quarto in action. On the left we see the Quarto source code, which is a combination of text and code. On the right we see the output of the Quarto source code as an HTML document.\n\n\n\n\n\n\n\n\nFigure 1: Quarto source (left) and output (right) example.\n\n\n\n\n\nQuarto documents generate various types of output: web documents (HTML), PDFs, Word documents, and many other types of output formats all based on the same source code. While the interleaving of code and prose to create a variety of output documents is one of the most attractive aspects of literate programming and Quarto, it is also possible to create documents with no code at all. It is a very versatile technology as you will come to appreciate.\n\n\n\n\n\n\n Dive deeper\nTo see Quarto in action, please check out the Quarto Gallery for a variety of examples of Quarto documents and their output.\n\n\n\nA Quarto source document is a plain-text file with the extension .qmd that can be opened in any plain text reader. We will be using the RStudio IDE (henceforth RStudio) to create, open, and edit, and generate output from .qmd files but any plain-text reader, such as TextEdit (MacOS) or Notepad (PC) can open these files.\nWith this in mind, let’s now move on to the anatomy of a Quarto document.\n\nAnatomy of a Quarto Document\nAt the most basic level a Quarto document contains two components:\n\na front-matter section and\na prose section.\n\nA third component, a code block, can be interleaved within the prose section to add code to the document. Let’s look at each of these in turn.\n\nFront-matter\nThe front matter of a Quarto document appears, well, at the front of the document (or the top, rather). Referring back to Figure Figure 1, we see the front matter at the top.\n---\ntitle: \"Introduction to Quarto\"\nauthor: \"Jerid Francom\"\nformat: html\n---\nWhen creating a Quarto document with RStudio the default attribute keys are title, author, and format. The front matter is fenced by three dashes ---.\nThe values for the first two keys are pretty straightforward and can be edited as needed. The value for the format attribute can also be edited to tell the .qmd file to generate other output types. Can you guess what value we might use to generate a PDF document? Yep, it’s just pdf. As we work Quarto you will learn more about how to use the RStudio interface to change some of these key-value pairs and add others!\n\n\nProse\nAnywhere below the front matter and not contained within a code block (see below) is open for prose. The prose section(s) have an added functionality in that they are Markdown aware. What does that mean, you say? Well, Markdown refers to a set of plain-text formatting conventions to produce formatted text in the output document. To quote Wikipedia:\n\nMarkdown is a lightweight markup language for creating formatted text using a plain-text editor. John Gruber and Aaron Swartz created Markdown in 2004 as a markup language that is appealing to human readers in its source code form. Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.\n\nWhat this enables us to do is to add simple text conventions to signal how the output should be formatted. Say we want to make some text bold. We just add ** around the text we want to appear bold.\n**bold text**\nWe can also do:\n\nitalics *italics*\nlinks [links](http://wfu.edu)\nstrikethrough ~~strikethrough~~\netc.\n\nFollow this link find more information on basic Markdown syntax.\n\n\nCode blocks\nCode blocks are where the R magic happens. Again, referring to Figure 1, we see that there is the following code block.\n```{r}\n1 + 1\n```\nA code block is bound by three backticks ```. After the first backticks the curly brackets {} allow us to tell Quarto which programming language to use to evaluate (i.e. run) in the code block. In most cases this will be R, hence the the opening curly bracket `{r}`. But there are other languages that can be used in Quarto, such as Python, SQL, and Bash.\nIn the previous example, R is used as a simple calculator adding 1 + 1. Here’s what this code block produces.\n\n1 + 1\n\n&gt; [1] 2\n\n\n```{r}\n#| label: add\n1 + 1\n```\nWe have only mentioned selecting the coding language and labeling the code block, but code blocks have various other options that can be used to determine how the code block should be used. Some common code block options are:\n\nhiding the code: #| echo: false\n\n```{r}\n#| label: add\n#| echo: false\n1 + 1\n```\n\n\n&gt; [1] 2\n\n\n\nhiding the output #| include: false\n\n```{r}\n#| label: add\n#| include: false\n1 + 1\n```\n\netc.\n\n\n\n\nCreate and render a Quarto document\nThe easiest and most efficient way to create a Quarto source file is to use the RStudio point-and-click interface. Just use the toolbar to create a new file and select “Quarto Document…”, as seen in Figure 2.\n\n\n\n\n\n\n\n\nFigure 2: Creating a new Quarto document in RStudio.\n\n\n\n\n\nThis will provide you a dialogue box asking you to add a title and author to the document and also allows you to select the type of document format to output, as seen in Figure 3.\n\n\n\n\n\n\n\n\nFigure 3: Dialogue box for creating a new Quarto document in RStudio.\n\n\n\n\n\nEnter a title and author and leave the format set to HTML.\nOn clicking ‘Create’ you will get a Quarto document, as in Figure 4, with some default/ boilerplate prose and code blocks. The prose and code blocks can be deleted, and we can start our own document.\n\n\n\n\n\n\n\n\nFigure 4: Quarto source in RStudio.\n\n\n\n\n\nBut for now, let’s leave things as they are and see how to generate the output report from this document. Click “Render” in the RStudio toolbar. Before it will render, you will be asked to save the file and give it a name.\nOnce you have done that the .qmd file will render in the format you have specified and open in the ‘Viewer’ pane, as seen in Figure 5.\n\n\n\n\n\n\n\n\nFigure 5: Quarto source and HTML output side-by-side in RStudio.\n\n\n\n\n\n\n\n\n\n\n\n Dive deeper\nWatch Getting Started with Quarto for a guided tour of Quarto (Çetinkaya-Rundel 2023)."
  },
  {
    "objectID": "recipes/recipe-00/index.html#check-your-understanding",
    "href": "recipes/recipe-00/index.html#check-your-understanding",
    "title": "0. Literate Programming",
    "section": "Check your understanding",
    "text": "Check your understanding\n\nTRUEFALSE Literate Programming, first introduced by Donald Knuth in 1984, allows the combination of computer code and text prose in one document.\nThe programming paradigm Literate Programming is implemented through QuartoRRStudioGitHub, a platform that facilitates the creation of a variety of output documents based on the same source code.\nWhich of the following components does a basic Quarto document not contain? Front-matter sectionProse sectionBack-matter sectionCode block\nTo generate a PDF document in Quarto, you can edit the format attribute value in the front-matter section to .\nTRUEFALSE The code block options echo and include can be used to hide the code and output, respectively.\nTRUEFALSE In Quarto, a code block, where the programming language code is entered, is bounded by three underscores (_)."
  },
  {
    "objectID": "recipes/recipe-00/index.html#lab-preparation",
    "href": "recipes/recipe-00/index.html#lab-preparation",
    "title": "0. Literate Programming",
    "section": "Lab preparation",
    "text": "Lab preparation\nThis concludes our introduction to literate programming using Quarto. We have covered the basics there but there is much more to explore.\nIn preparation for Lab 0, ensure that you have completed the following:\n\nSetup your computing environment with R and RStudio\nInstalled the necessary packages:\n\nquarto\ntinytex\n\n\nand that you are prepared to do the following:\n\nOpen RStudio and understand the basic interface\nCreate, edit, and render Quarto documents\nUse some basic Markdown syntax to format text\n\nWith this in mind, you are ready to move on to Lab 00."
  },
  {
    "objectID": "recipes/recipe-06/index.html",
    "href": "recipes/recipe-06/index.html",
    "title": "Recipe 06",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "recipes/recipe-08/index.html",
    "href": "recipes/recipe-08/index.html",
    "title": "Recipe 08",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "instructors.html#materials",
    "href": "instructors.html#materials",
    "title": "Instructors",
    "section": "Materials",
    "text": "Materials\n\nSlide decks\n\n\nExercises"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "recipes/recipe-01/index.html",
    "href": "recipes/recipe-01/index.html",
    "title": "1. Academic writing with Quarto",
    "section": "",
    "text": "Skills\n\nNumbered sections\nTable of contents\nCross-referencing tables and figures\nIn-line citations and references list"
  },
  {
    "objectID": "recipes/recipe-01/index.html#concepts-and-strategies",
    "href": "recipes/recipe-01/index.html#concepts-and-strategies",
    "title": "1. Academic writing with Quarto",
    "section": "Concepts and strategies",
    "text": "Concepts and strategies\nFor many of the style components that we use in Quarto, there is a part that is addressed in the front-matter section and a part that is addressed in the prose section and/ or code block sections.\nTo refresh our memory, the front-matter is fenced by three dashes (---) and is where we set the document attributes. The prose section is where we write the text of the document. The code block section is where we write the code that will be executed and is fenced by three backticks (```) and the name of the code interpreter {r} (R for us).\n---\n1title: \"My document title\"\n2format: pdf\n---\n\n3This is the prose section.\n\n4```{r}\n#| label: example-code-block\n1 + 1\n```\n\n1\n\nThe title of the document\n\n2\n\nThe format of the document\n\n3\n\nThe prose section\n\n4\n\nThe code block section\n\n\nWith this in mind let’s look at each of these elements in turn.\n\nNumbered sections\nTo number sections in Quarto, we use the number_sections key with the value yes. This is set in the front-matter section, nested under the value for the document type to be rendered. For example, to number sections in a PDF document, we would set the number-sections key to true in the front-matter section as follows:\n---\n1title: \"My document title\"\n2format:\n3  pdf:\n4    number-sections: true\n---\n\n1\n\nThe title of the document\n\n2\n\nThe format of the document\n\n3\n\nThe type of document to be rendered, note the identation\n\n4\n\nThe key-value pair to number sections in the PDF document, again note the identation\n\n\nHeaders in the prose section are then numbered automatically. For example, the following markdown:\n# Section\n\n## Subsection\n\n### Subsubsection\n\n#### Subsubsubsection\n\n##### Subsubsubsubsection\nwould render as:\n\n\n\n\n\n\n\n\n\nWe can also control the depth of the numbering by setting the number-depth key in the front-matter section. For example, to number sections and subsections, but not subsubsections, we would set the number-depth key to 2 as follows:\n---\ntitle: \"My document title\"\nformat:\n  pdf:\n    number-sections: true\n1    number-depth: 2\n---\n\n1\n\nThe key-value pair to control the depth of the numbering\n\n\nNow the first and second headers are numbered and formated but third and subsequent headers are only formatted.\nIf for some reason you want to turn off numbering for a specific header, you can add {.unnumbered} to the end of the header. For example, the following markdown:\n# Section {.unnumbered}\nThis is particularly useful in academic writing when we want to add a reference, materials, or other section that is not numbered at the end of the document.\n\n\n\n\n\n\n Warning\nNote that if you have a header that is unnumbered, the next header will be numbered as if the unnumbered header did not exist. This can have unexpected results if you have children of an unnumbered header.\n\n\n\n\n\nTable of contents\nFor longer documents including a table of contents can be a useful way to help readers navigate the document. To include a table of contents in Quarto, we use the toc key with the value true. Again, in the front-matter section, nested under the format value, as seen below:\n---\ntitle: \"My document title\"\nformat:\n  pdf:\n1    toc: true\n---\n\n1\n\nThe key-value pair to include a table of contents in the PDF document\n\n\n\n\n\n\n\n\n Tip\nFor PDF and Word document outputs, the table of contents will be automatically generated and placed at the beginning of the document. For HTML documents, the table of contents will be placed in the sidebar by default.\n\n\n\nIf if our headers are numbered, they will appeared numbered in the table of contents. If we unnnumbered a header, it will not appear with a section number. As with section numbering, we can also control the depth of the table of contents by setting the toc-depth key in the front-matter section. For example, to include sections and subsections, but not subsubsections, we would set the toc-depth key to 2 as follows:\n---\ntitle: \"My document title\"\nformat:\n  pdf:\n    toc: true\n1    toc-depth: 2\n---\n\n1\n\nThe key-value pair to control the depth of the table of contents\n\n\nAnd as with section numbering we can avoid listing a header in the table of contents by adding {.unlisted} to the end of the header.\n\n\nCross-referencing tables and figures\nAnother key element in academic writing are using cross-references to tables and figures. This allows us to refer to a table or figure by number without having to manually update the number if we add or remove a table or figure.\nIn this case, we will not need to add anything to the front-matter section. Instead, we will modify keys in the code block section of a code-generated table or figure.\nTo cross-reference a table or figure, we need to add a prefix to the label key’s value. The prefix, either tbl- or fig-, indicates whether the label is for a table or figure. Additionally, table or figure captions can be added with the tbl-cap or fig-cap keys, respectively.\nLet’s look at a basic figure that we can cross-reference. The following code block will generate a very simple scatterplot.\n```{r}\n1#| label: fig-scatterplot\n2#| fig-cap: \"A scatterplot\"\n\nplot(x = 1:10, y = 1:10)\n```\n\n3In @fig-scatterplot we see a scatterplot. ....\n\n1\n\nThe label for the figure. Includes fig- as a prefix.\n\n2\n\nThe caption for the figure.\n\n3\n\nThe in-line reference to the figure. Uses the @ symbol followed by the label value.\n\n\n\n\n\n\n\n\n\nplot(1:10, 1:10)\n\n\n\n\n\n\n\nFigure 1: A scatterplot\n\n\n\n\n\nIn Figure 1 we see a scatterplot. …\n\n\n\nFor tables generated by R, the process is very similar to that of figures. The only difference is that we use the tbl- prefix on the label value and the tbl-cap key instead of the fig-cap key for the caption.\nWe can also create tables using markdown syntax. In this case, the format is a little different. Consider Table Table 1, for example.\n| Column 1 | Column 2 | Column 3 |\n|----------|----------|----------|\n| A        | B        | C        |\n| D        | E        | F        |\n\n: A simple table {#tbl-table-1}\n\n\n\n\n\n\n\n\n\nTable 1: A simple table\n\n\n\n\n\nColumn 1\nColumn 2\nColumn 3\n\n\n\n\nA\nB\nC\n\n\nD\nE\nF\n\n\n\n\n\n\n\n\n\n\n\nIn-line citations and references list\nThe last element we will cover here is adding citations and a references list to a Quarto document. To add citations we need three things:\n\nA bibliography file\nA reference to the bibliography file in the front-matter section\nA citation in the prose section which is contained in the bibliography file\n\nThe bibliography file is a plain text file that contains the citations that we want to use in our document. The file requires the extension .bib and is formatted using the BibTeX format. BibTeX is a reference syntax that is commonly used in academia.\nLet’s take a look at a sample file, bibliography.bib, that contains a single reference.\n@Manual{R-dplyr,\n  title = {dplyr: A Grammar of Data Manipulation},\n  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller and Davis Vaughan},\n  year = {2023},\n  note = {R package version 1.1.4},\n  url = {https://dplyr.tidyverse.org},\n}\nIn this file, we can see that the reference is for a manual entry with @Manual. The type of entry will change what fields are relevant and/ or required. In this entry, we have the cite key R-dplyr, the title, the authors, the year, a note, and a URL. Other entries, and entry types will have different fields.\nYou can find BibTeX formatted references almost everywhere you can find scholarly work. For example, Google Scholar, Web of Science, and Scopus all provide BibTeX formatted references. Additionally, many journals provide BibTeX formatted references for the articles they publish.\n\n\n\n\n\n\n Dive deeper\nManaging your references can be a challenge if you begin to amass a large number of them. There are a number of tools that can help you manage your references. For example, Zotero is a free, open-source reference manager that can help you organize your references and generate BibTeX formatted references.\nZotero also has a browser extension that allows you to easily add references to your Zotero library from your browser.\nFurthermore, Zotero can be connected to RStudio to facilitate the incorporation of BibTeX formatted references in a Quarto document. See the RStudio documentation for more information.\n\n\n\nIn the front-matter of our Quarto document, we need to add a reference to the bibliography file. This is done using the bibliography key. For example, if our bibliography file is called bibliography.bib and is located in the same directory as our Quarto document, we would add the following to the front-matter section:\n---\ntitle: \"My document title\"\nformat: pdf\n1bibliography: bibliography.bib\n---\n\n1\n\nThe key-value pair to include a path to the file which contains the BibTeX formatted references.\n\n\nWith the bibliography file and the reference to the bibliography file in the front-matter section, we can now add citations to our document. To do this, we use the @ symbol followed by the citation key in the prose section. For example, to cite the R-dplyr reference from the bibliography.bib file, we would add @R-dplyr to the prose section as follows:\nThis is a citation to @R-dplyr.\nThe citation will appear as below in the rendered document.\n\n\n\n\n\n\nThis is a citation to Wickham et al. (2023).\n\n\n\nAnd automatically, on rendering the document, a references list will be added to the end of the document. For this reason if you have citations in your document, it is a good idea to include a header section # References at the end of your document.\n\n\n\n\n\n\n Tip\nThere are a number of ways of having your inline citations appear. For example, in parentheses, with multiple citations, only with the year, adding a page number, etc.. For more information on how to format your citations, see the Quarto documentation."
  },
  {
    "objectID": "recipes/recipe-01/index.html#check-your-understanding",
    "href": "recipes/recipe-01/index.html#check-your-understanding",
    "title": "1. Academic writing with Quarto",
    "section": "Check your understanding",
    "text": "Check your understanding\n\nConsider the following front-matter sections, A and B.\n\n\n\n\n\n\nA\n---\ntitle: \"My document title\"\nformat:\n  pdf:\n    number-sections: true\n    number-depth: 3\n    toc: false\n---\n\n\n\n\n\n\n\n\n\nB\n---\ntitle: \"My document title\"\nformat:\n  pdf:\n    number-sections: true\n    toc: true\n    toc-depth: 2\n---\n\n\n\nChoose whether the following statements are true or false.\n\nTRUEFALSE Section numbering will be included in the PDF output for both A and B.\nTRUEFALSE Section numbering will be applied to the first three levels of headers in the PDF output for both A and B.\nTRUEFALSE A table of contents will be included in the PDF output for both A and B.\nTRUEFALSE A table of contents will be included in the PDF output for B, but will only include the first two levels of headers.\n\nNow respond to the following questions.\n\n@tbl-scatterplot@fig-scatterplot@scatterplot will cross-reference a figure with the label fig-scatterplot.\n is the front-matter key to include a path to the file which contains the BibTeX formatted references."
  },
  {
    "objectID": "recipes/recipe-01/index.html#lab-preparation",
    "href": "recipes/recipe-01/index.html#lab-preparation",
    "title": "1. Academic writing with Quarto",
    "section": "Lab preparation",
    "text": "Lab preparation\nThis rounds out our introduction to academic writing in Quarto. In Lab 1 you will have an opportunity to practice these concepts by doing an article summary which includes some of these features using Quarto.\nIn preparation for Lab 1, ensure that you are prepared to do the following:\n\nEdit the front-matter section of a Quarto document to render:\n\na PDF document or a Word document\na document with numbered sections\na document with a table of contents\na document with a path to a bibliography file\n\nAdd an inline citation to the prose section of a Quarto document\n\nAlso, since you will do an article summary, you should be prepared with:\n\nan article of interest related to text analysis that you have read or at least skimmed for the following:\n\nthe research question\nthe data used\nthe methods used\nthe results/ findings of the study\n\na BibTeX formatted reference for the article\n\n\n\n\n\n\n\nIf you do not find an article of interest, you can use Bychkovska and Lee (2017)."
  },
  {
    "objectID": "recipes/recipe-07/index.html",
    "href": "recipes/recipe-07/index.html",
    "title": "Recipe 07",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "recipes/recipe-09/index.html",
    "href": "recipes/recipe-09/index.html",
    "title": "Recipe 09",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "recipes/recipe-05/index.html",
    "href": "recipes/recipe-05/index.html",
    "title": "Recipe 05",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "recipes/recipe-03/index.html",
    "href": "recipes/recipe-03/index.html",
    "title": "3. Descriptive assessment of datasets",
    "section": "",
    "text": "Skills\n\nSummary overviews of datasets with skimr\nSummary statistics with dplyr\nCreating Quarto tables with knitr\nCreating Quarto plots with ggplot2"
  },
  {
    "objectID": "recipes/recipe-03/index.html#concepts-and-strategies",
    "href": "recipes/recipe-03/index.html#concepts-and-strategies",
    "title": "3. Descriptive assessment of datasets",
    "section": "Concepts and strategies",
    "text": "Concepts and strategies\nIn this Recipe, we will use the PassiveBrownFam dataset from the corpora package (Evert 2023). This dataset contains information on the passive voice usage in the Brown family of corpora. The dataset contains 11 variables and 2,449 observations.\nI have assigned this dataset to the object brown_fam_df and have made minor modifications to the variable names to improve the readability of the dataset.\n\n\n# Load packages\nlibrary(dplyr)\n\n# Read the dataset from the `corpora` package\nbrown_fam_df &lt;-\n  corpora::PassiveBrownFam |&gt; # reference the dataset\n  as_tibble() # convert to a tibble\n\n# Rename variables\nbrown_fam_df &lt;-\n  brown_fam_df |&gt; # pass the original dataset\n  rename( # rename variables: new_name = old_name\n    lang_variety = lang,\n    num_words = n.words,\n    active_verbs = act,\n    passive_verbs = pass,\n    total_verbs = verbs,\n    percent_passive = p.pass\n  )\n\n# Preview\nglimpse(brown_fam_df)\n\n&gt; Rows: 2,499\n&gt; Columns: 11\n&gt; $ id              &lt;chr&gt; \"brown_A01\", \"brown_A02\", \"brown_A03\", \"brown_A04\", \"b…\n&gt; $ corpus          &lt;fct&gt; Brown, Brown, Brown, Brown, Brown, Brown, Brown, Brown…\n&gt; $ section         &lt;fct&gt; A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, …\n&gt; $ genre           &lt;fct&gt; press reportage, press reportage, press reportage, pre…\n&gt; $ period          &lt;fct&gt; 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, …\n&gt; $ lang_variety    &lt;fct&gt; AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE, AmE,…\n&gt; $ num_words       &lt;int&gt; 2080, 2116, 2051, 2095, 2111, 2102, 2099, 2069, 2058, …\n&gt; $ active_verbs    &lt;int&gt; 164, 154, 135, 128, 170, 166, 165, 163, 153, 169, 132,…\n&gt; $ passive_verbs   &lt;int&gt; 40, 25, 34, 25, 32, 21, 31, 19, 39, 23, 17, 10, 15, 26…\n&gt; $ total_verbs     &lt;int&gt; 204, 179, 169, 153, 202, 187, 196, 182, 192, 192, 149,…\n&gt; $ percent_passive &lt;dbl&gt; 19.61, 13.97, 20.12, 16.34, 15.84, 11.23, 15.82, 10.44…\n\n\nYou can learn more about these variables by reading the dataset documentation with ?corpora::PassiveBrownFam.\n\nStatistical overviews\nUnderstanding our data is of utmost importance before, during, and after analysis. After we get to know our data by inspecting the data origin, dictionary, and structure, we then move to summarizing the data.\nA statistical overview of the data is a good place to start as it gives us a sense of all of the variables and variable types in the dataset. We can use the skimr package to create a statistical overview of the data, using the very convienent skim() function.\nLet’s create a statistical overview of the brown_fam_df dataset.\n\n# Load packages\nlibrary(skimr)\n\n# Create a statistical overview of the `brown_fam_df` dataset\nskim(brown_fam_df)\n\n\n# ── Data Summary ────────────────────────\n#                            Values      \n# Name                       brown_fam_df\n# Number of rows             2499        \n# Number of columns          11          \n# _______________________                \n# Column type frequency:                 \n#   character                1           \n#   factor                   5           \n#   numeric                  5           \n# ________________________               \n# Group variables            None        \n# \n# ── Variable type: character ────────────────────────────────────────────────────\n#   skim_variable n_missing complete_rate min max empty n_unique whitespace\n# 1 id                    0             1   7   9     0     2499          0\n# \n# ── Variable type: factor ───────────────────────────────────────────────────────\n#   skim_variable n_missing complete_rate ordered n_unique\n# 1 corpus                0             1 FALSE          5\n# 2 section               0             1 FALSE         15\n# 3 genre                 0             1 FALSE         15\n# 4 period                0             1 FALSE          3\n# 5 lang_variety          0             1 FALSE          2\n#   top_counts                            \n# 1 BLO: 500, Bro: 500, LOB: 500, FLO: 500\n# 2 J: 400, G: 381, F: 228, A: 220        \n# 3 lea: 400, bel: 381, pop: 228, pre: 220\n# 4 196: 1000, 199: 999, 193: 500         \n# 5 BrE: 1500, AmE: 999                   \n# \n# ── Variable type: numeric ──────────────────────────────────────────────────────\n#   skim_variable   n_missing complete_rate   mean    sd       p0     p25    p50\n# 1 num_words               0             1 2165.  97.8  1406     2127    2163  \n# 2 active_verbs            0             1  179.  56.6    39      139     170  \n# 3 passive_verbs           0             1   25.7 12.9     2       16      23  \n# 4 total_verbs             0             1  204.  49.1    66      170     196  \n# 5 percent_passive         0             1   14.0  9.13    0.612    7.39   12.1\n#      p75   p100 hist \n# 1 2200   4397   ▁▇▁▁▁\n# 2  214    551   ▃▇▂▁▁\n# 3   32     86   ▆▇▂▁▁\n# 4  234    571   ▃▇▂▁▁\n# 5   18.2   67.7 ▇▅▁▁▁\n\n\nThe output of the skim() function contains a lot of information but it essentially has two parts: a summary of the dataset and a summary of each variable in the dataset. The summary of each of the variables, however, is grouped by variable type. Remember, each of our variables in a data frame is a vector and each vector has a type.\nWe have already learned about different types of vectors in R, including character, numeric, and logical. In this dataset, we are presented with a new type of vector: a factor. A factor is essentially a character vector that contains a set of discrete values, or levels. Factors can be ordered or unordered and can contain levels that are not present in the data.\nNow, looking at each of the variable types, we can see that we have 1 character variable, 5 factor variables, and 5 numeric variables. Each of these variable types assume a different set of summary statistics. For example, we can calculate the mean of a numeric variable but not of a character variable. Or, we can count the number of unique values in a character variable but not in a numeric variable.\nFor all variables, skim() will also provide the number of missing values and the percent of non-missing values.\nInspecting the entire dataset is a good place to start but at some point we often want focus in on a set of variables. We can add the yank() function to extract the statistical overview of a set of variables by their variable types.\nLet’s extract the statistical overview of the numeric variables in the brown_fam_df dataset.\n\n# Extract the statistical overview of the numeric variables\nbrown_fam_df |&gt;\n  skim() |&gt;\n  yank(\"numeric\")\n\n── Variable type: numeric ─────────────────────────────────────────────────────────────────────────\n  skim_variable   n_missing complete_rate   mean    sd       p0     p25    p50    p75   p100 hist\n1 num_words               0             1 2165.  97.8  1406     2127    2163   2200   4397   ▁▇▁▁▁\n2 active_verbs            0             1  179.  56.6    39      139     170    214    551   ▃▇▂▁▁\n3 passive_verbs           0             1   25.7 12.9     2       16      23     32     86   ▆▇▂▁▁\n4 total_verbs             0             1  204.  49.1    66      170     196    234    571   ▃▇▂▁▁\n5 percent_passive         0             1   14.0  9.13    0.612    7.39   12.1   18.2   67.7 ▇▅▁▁▁\n\n\nSummary statistics of particular variables\nThese summary statistics are useful but for a preliminary and interactive use, but it is oftent the case that we will want to focus in on a particular variable or set of variables and their potential relationships to other variables.\nWe can use the dplyr package to calculate summary statistics for a particular variable or set of variables. We can use the group_by() function to group the data by a particular variable or variables. Then we can use the summarize() function to calculate summary statistics for the grouped data.\nFor example, let’s calculate the mean and median of the percent_passive variable in the brown_fam_df dataset grouped by the lang_variety variable.\n\n# Mean and median of `percent_passive` grouped by `lang_variety`\nbrown_fam_df |&gt;\n  group_by(lang_variety) |&gt;\n  summarize(\n    mean_percent_passive = mean(percent_passive),\n    median_percent_passive = median(percent_passive)\n  )\n\n&gt; # A tibble: 2 × 3\n&gt;   lang_variety mean_percent_passive median_percent_passive\n&gt;   &lt;fct&gt;                       &lt;dbl&gt;                  &lt;dbl&gt;\n&gt; 1 AmE                          12.9                   11.0\n&gt; 2 BrE                          14.8                   13.3\n\n\nThe result is a 2x3 data frame which includes both the mean and median of the percent_passive variable for each of the two levels of the lang_variety variable.\nThe group_by() function can also be used to group by multiple variables. For example, let’s calculate the mean and median of the percent_passive variable in the brown_fam_df dataset grouped by the lang_variety and genre variables.\n\n# Mean and median of `percent_passive` grouped by\n# `lang_variety` and `genre`\nbrown_fam_df |&gt;\n  group_by(lang_variety, genre) |&gt;\n  summarize(\n    mean_percent_passive = mean(percent_passive),\n    median_percent_passive = median(percent_passive)\n  )\n\n&gt; # A tibble: 30 × 4\n&gt; # Groups:   lang_variety [2]\n&gt;    lang_variety genre            mean_percent_passive median_percent_passive\n&gt;    &lt;fct&gt;        &lt;fct&gt;                           &lt;dbl&gt;                  &lt;dbl&gt;\n&gt;  1 AmE          press reportage                 11.5                   11.0 \n&gt;  2 AmE          press editorial                 10.6                   10.1 \n&gt;  3 AmE          press reviews                    9.54                   9.77\n&gt;  4 AmE          religion                        14.3                   14.3 \n&gt;  5 AmE          skills / hobbies                14.9                   13.9 \n&gt;  6 AmE          popular lore                    14.0                   12.7 \n&gt;  7 AmE          belles lettres                  12.0                   11.7 \n&gt;  8 AmE          miscellaneous                   23.5                   23.3 \n&gt;  9 AmE          learned                         21.3                   18.3 \n&gt; 10 AmE          general fiction                  6.22                   5.89\n&gt; # ℹ 20 more rows\n\n\nFor numeric variables, such as percent_passive, there are a number of summary statistics that we can calculate. We’ve seen the R functions for mean and median but we can also calculate the standard deviation (sd()), variance (var()), minimum (min()), maximum (max()), interquartile range (IQR()), median absolute deviation (mad()), and quantiles (quantile()). All these calculations make sense for numeric variables but not for character variables.\nFor character variables, and factors, the summary statistics are more limited. We can calculate the number of observations (n()) and/ or the number of unique values (n_distinct()). Let’s now summarize the number of observations n() grouped by the genre variable in the brown_fam_df dataset.\n\n# Frequency table for `genre`\nbrown_fam_df |&gt;\n  group_by(genre) |&gt;\n  summarize(\n    n = n(),\n  )\n\n&gt; # A tibble: 15 × 2\n&gt;    genre                n\n&gt;    &lt;fct&gt;            &lt;int&gt;\n&gt;  1 press reportage    220\n&gt;  2 press editorial    135\n&gt;  3 press reviews       85\n&gt;  4 religion            85\n&gt;  5 skills / hobbies   186\n&gt;  6 popular lore       228\n&gt;  7 belles lettres     381\n&gt;  8 miscellaneous      150\n&gt;  9 learned            400\n&gt; 10 general fiction    145\n&gt; 11 detective          120\n&gt; 12 science fiction     30\n&gt; 13 adventure          144\n&gt; 14 romance            145\n&gt; 15 humour              45\n\n\nJust as before, we can add multiple grouping variables to group_by(). Let’s add lang_variety to the grouping and calculate the number of observations n() grouped by the genre and lang_variety variables in the brown_fam_df dataset.\n\n# Cross-tabulation for `genre` and `lang_variety`\nbrown_fam_df |&gt;\n  group_by(genre, lang_variety) |&gt;\n  summarize(\n    n = n(),\n  )\n\n&gt; # A tibble: 30 × 3\n&gt; # Groups:   genre [15]\n&gt;    genre            lang_variety     n\n&gt;    &lt;fct&gt;            &lt;fct&gt;        &lt;int&gt;\n&gt;  1 press reportage  AmE             88\n&gt;  2 press reportage  BrE            132\n&gt;  3 press editorial  AmE             54\n&gt;  4 press editorial  BrE             81\n&gt;  5 press reviews    AmE             34\n&gt;  6 press reviews    BrE             51\n&gt;  7 religion         AmE             34\n&gt;  8 religion         BrE             51\n&gt;  9 skills / hobbies AmE             72\n&gt; 10 skills / hobbies BrE            114\n&gt; # ℹ 20 more rows\n\n\n\n\n\n\n\n\n Tip\nThe result of calculating the number of observations for a character or factor variable is known as a frequency table. Grouping two or more categorical variables is known as a cross-tabulation or a contingency table.\n\n\n\nNow, we can also pipe the results of a group_by() and summarize() to another function. This can be to say sort, select, or filter the results. It can also be to perform another summary function. It is important, however, to remember that the result of a group_by() produces a grouped data frame. Subsequent functions will be applied to the grouped data frame. This can lead to unexpected results if the original grouping is not relevant for the subsequent function. To avoid this, we can use the ungroup() function to remove the grouping after the relevant grouped summary statistics have been calculated.\nLet’s return to calculating the number of observations n() grouped by the genre and lang_variety variables in the brown_fam_df dataset. But let’s add another summary which uses the n variable to calculate the mean and median number of observations.\nIf we do not use the ungroup() function, the mean and median will be calculated for each genre collapsed across lang_variety.\n\n# Mean and median of `n` grouped by `genre`\nbrown_fam_df |&gt;\n  group_by(genre, lang_variety) |&gt;\n  summarize(\n    n = n(),\n  ) |&gt;\n  summarize(\n    mean_n = mean(n),\n    median_n = median(n)\n  )\n\n&gt; # A tibble: 15 × 3\n&gt;    genre            mean_n median_n\n&gt;    &lt;fct&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n&gt;  1 press reportage   110      110  \n&gt;  2 press editorial    67.5     67.5\n&gt;  3 press reviews      42.5     42.5\n&gt;  4 religion           42.5     42.5\n&gt;  5 skills / hobbies   93       93  \n&gt;  6 popular lore      114      114  \n&gt;  7 belles lettres    190.     190. \n&gt;  8 miscellaneous      75       75  \n&gt;  9 learned           200      200  \n&gt; 10 general fiction    72.5     72.5\n&gt; 11 detective          60       60  \n&gt; 12 science fiction    15       15  \n&gt; 13 adventure          72       72  \n&gt; 14 romance            72.5     72.5\n&gt; 15 humour             22.5     22.5\n\n\nTherefore we see that we have a mean and median calculated for the number of documents in the corpus for each of the 15 genres.\nIf we use the ungroup() function, the mean and median will be calculated for all genres. Note we will use the ungroup() function between these summaries to clear the grouping before calculating the mean and median.\n\n# Number of observations for each `genre` and `lang_variety`\nbrown_fam_df |&gt;\n  group_by(genre, lang_variety) |&gt;\n  summarize(\n    n = n(),\n  ) |&gt;\n  ungroup() |&gt;\n  summarize(\n    mean_n = mean(n),\n    median_n = median(n)\n  )\n\n&gt; # A tibble: 1 × 2\n&gt;   mean_n median_n\n&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n&gt; 1   83.3       72\n\n\nNow we see that we have a mean and median calculated across all genres.\n\nBefore we leave this section, let’s look some other ways to create frequency and contingency tables for character and factor variables. A shortcut to calculate a frequency table for a character or factor variable is to use the count() function from the dplyr package.\nLet’s calculate the number of observations grouped by the genre variable in the brown_fam_df dataset.\n\n# Frequency table for `genre`\nbrown_fam_df |&gt;\n  count(genre)\n\n&gt; # A tibble: 15 × 2\n&gt;    genre                n\n&gt;    &lt;fct&gt;            &lt;int&gt;\n&gt;  1 press reportage    220\n&gt;  2 press editorial    135\n&gt;  3 press reviews       85\n&gt;  4 religion            85\n&gt;  5 skills / hobbies   186\n&gt;  6 popular lore       228\n&gt;  7 belles lettres     381\n&gt;  8 miscellaneous      150\n&gt;  9 learned            400\n&gt; 10 general fiction    145\n&gt; 11 detective          120\n&gt; 12 science fiction     30\n&gt; 13 adventure          144\n&gt; 14 romance            145\n&gt; 15 humour              45\n\n\nWe can also add multiple grouping variables to count() and create contingency tables.\nLet’s add lang_variety to the grouping and create a cross-tabulation for genre and lang_variety variables in the brown_fam_df dataset.\n\n# Cross-tabulation for `genre` and `lang_variety`\nbrown_fam_df |&gt;\n  count(genre, lang_variety)\n\n&gt; # A tibble: 30 × 3\n&gt;    genre            lang_variety     n\n&gt;    &lt;fct&gt;            &lt;fct&gt;        &lt;int&gt;\n&gt;  1 press reportage  AmE             88\n&gt;  2 press reportage  BrE            132\n&gt;  3 press editorial  AmE             54\n&gt;  4 press editorial  BrE             81\n&gt;  5 press reviews    AmE             34\n&gt;  6 press reviews    BrE             51\n&gt;  7 religion         AmE             34\n&gt;  8 religion         BrE             51\n&gt;  9 skills / hobbies AmE             72\n&gt; 10 skills / hobbies BrE            114\n&gt; # ℹ 20 more rows\n\n\nNote that the results of count() are not grouped so we do not need to use the ungroup() function before calculating subsequent summary statistics.\nAnother way to create frequency and contingency tables is to use the tabyl() function from the janitor package (Firke 2023). Let’s create a frequency table for the genre variable in the brown_fam_df dataset.\n\n# Load packages\nlibrary(janitor)\n\n# Frequency table for `genre`\nbrown_fam_df |&gt;\n  tabyl(genre)\n\n&gt;             genre   n percent\n&gt;   press reportage 220  0.0880\n&gt;   press editorial 135  0.0540\n&gt;     press reviews  85  0.0340\n&gt;          religion  85  0.0340\n&gt;  skills / hobbies 186  0.0744\n&gt;      popular lore 228  0.0912\n&gt;    belles lettres 381  0.1525\n&gt;     miscellaneous 150  0.0600\n&gt;           learned 400  0.1601\n&gt;   general fiction 145  0.0580\n&gt;         detective 120  0.0480\n&gt;   science fiction  30  0.0120\n&gt;         adventure 144  0.0576\n&gt;           romance 145  0.0580\n&gt;            humour  45  0.0180\n\n\nIn addition to providing frequency counts, the tabyl() function also provides the percent of observations for each level of the variable. And, we can add up to three grouping variables to tabyl() as well.\nLet’s add lang_variety to the grouping and create a contingency table for the genre and lang_variety variables in the brown_fam_df dataset.\n\n# Cross-tabulation for `genre` and `lang_variety`\nbrown_fam_df |&gt;\n  tabyl(genre, lang_variety)\n\n&gt;             genre AmE BrE\n&gt;   press reportage  88 132\n&gt;   press editorial  54  81\n&gt;     press reviews  34  51\n&gt;          religion  34  51\n&gt;  skills / hobbies  72 114\n&gt;      popular lore  96 132\n&gt;    belles lettres 150 231\n&gt;     miscellaneous  60  90\n&gt;           learned 160 240\n&gt;   general fiction  58  87\n&gt;         detective  48  72\n&gt;   science fiction  12  18\n&gt;         adventure  57  87\n&gt;           romance  58  87\n&gt;            humour  18  27\n\n\nThe results do not include the percent of observations for each level of the variable as it is not clear how to calculate the percent of observations for each level of the variable when there are multiple grouping variables. We must specify if we want to calculate the percent of observations by row or by column.\n\n\n\n\n\n\n Dive deeper\nThe janitor package includes a variety of adorn_*() functions to add additional information to the results of tabyl(), including percentages, frequencies, and totals. Feel free to explore these functions on your own. We will return to this topic again later in the course.\n\n\n\n\n\nCreating Quarto tables\nSummarizing the data is not only useful for our understanding of the data as part of our analysis but also for communicating the data in reports, manuscripts, and presentations.\nOne way to communicate summary statistics is with tables. In Quarto, we can use the knitr package (Xie 2023) in combination with code block options to produce formatted tables which we can cross-reference in our prose sections.\nLet’s create an object from the cross-tabulation for the genre and lang_variety variables in the brown_fam_df dataset to work with.\n\n# Cross-tabulation for `genre` and `lang_variety`\nbf_genre_lang_ct &lt;-\n  brown_fam_df |&gt;\n  tabyl(genre, lang_variety)\n\nTo create a table in Quarto, we use the kable() function. The kable() function takes a data frame (or matrix) as an argument. The format argument will be derived from the Quarto document format (‘html’, ‘pdf’, etc.).\n\n# Load packages\nlibrary(knitr)\n\n# Create a table in Quarto\nkable(bf_genre_lang_ct)\n\n\n\n\ngenre\nAmE\nBrE\n\n\n\n\npress reportage\n88\n132\n\n\npress editorial\n54\n81\n\n\npress reviews\n34\n51\n\n\nreligion\n34\n51\n\n\nskills / hobbies\n72\n114\n\n\npopular lore\n96\n132\n\n\nbelles lettres\n150\n231\n\n\nmiscellaneous\n60\n90\n\n\nlearned\n160\n240\n\n\ngeneral fiction\n58\n87\n\n\ndetective\n48\n72\n\n\nscience fiction\n12\n18\n\n\nadventure\n57\n87\n\n\nromance\n58\n87\n\n\nhumour\n18\n27\n\n\n\n\n\nTo add a caption to the table and to enable cross-referencing, we use the code block options label and tbl-cap. The label option takes a label prefixed with tbl- to create a cross-reference to the table. The tbl-cap option takes a caption for the table, in quotation marks.\n#| label: tbl-brown-genre-lang-ct\n#| tbl-cap: \"Cross-tabulation of `genre` and `lang_variety`\"\n\n# Create a table in Quarto\nkable(bf_genre_lang_ct)\nNow we can cross-reference the table with the @tbl-brown-genre-lang-ct syntax. So the following Quarto document will produce the following prose with a cross-reference to the formatted table output.\n\nAs we see in @tbl-brown-genre-lang-ct, the distribution of `genre` is similar across `lang_variety`.\n\n```{r}\n#| label: tbl-brown-genre-lang-ct\n#| tbl-cap: \"Cross-tabulation of `genre` and `lang_variety`\"\n\n# Print cross-tabulation\nkable(bf_genre_lang_ct)\n```\n\nAs we see in Table 1, the distribution of genre is similar across lang_variety.\n\n\n\n\nTable 1: Cross-tabulation of genre and lang_variety\n\n\n\n\n\n\ngenre\nAmE\nBrE\n\n\n\n\npress reportage\n88\n132\n\n\npress editorial\n54\n81\n\n\npress reviews\n34\n51\n\n\nreligion\n34\n51\n\n\nskills / hobbies\n72\n114\n\n\npopular lore\n96\n132\n\n\nbelles lettres\n150\n231\n\n\nmiscellaneous\n60\n90\n\n\nlearned\n160\n240\n\n\ngeneral fiction\n58\n87\n\n\ndetective\n48\n72\n\n\nscience fiction\n12\n18\n\n\nadventure\n57\n87\n\n\nromance\n58\n87\n\n\nhumour\n18\n27\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Dive deeper\nThe kableExtra package (Zhu 2024) provides additional functionality for formatting tables in Quarto.\n\n\n\n\n\nCreating Quarto plots\nWhere tables are useful for communicating summary statistics for numeric and character variables, plots are useful for communicating relationships between variables especially when one or more of the variables is numeric. Furthermore, for complex relationships, plots can be more effective than tables.\nIn Quarto, we can use the ggplot2 package (Wickham et al. 2024) in combination with code block options to produce formatted plots which we can cross-reference in our prose sections.\nLet’s see this in action with a simple histogram of the percent_passive variable in the brown_fam_df dataset. The Quarto document will produce the following prose with a cross-reference to the formatted plot output.\nAs we see in @fig-brown-fam-percent-passive-hist, the distribution of `percent_passive` is skewed to the right.\n\n```{r}\n#| label: fig-brown-fam-percent-passive-hist\n#| fig-cap: \"Histogram of `percent_passive`\"\n\n# Create a histogram in Quarto\nggplot(brown_fam_df) +\n  geom_histogram(aes(x = percent_passive))\n```\n\nAs we see in Figure 1, the distribution of percent_passive is skewed to the right.\n\n\n\n\n\n\n\n\nFigure 1: Histogram of percent_passive\n\n\n\n\n\n\nThe ggplot2 package implements the ‘Grammar of Graphics’ approach to creating plots. This approach is based on the idea that plots can be broken down into components, or layers, and that each layer can be manipulated independently.\nThe main components are data, aesthetics, and geometries. Data is the data frame that contains the variables to be plotted. Aesthetics are the variables that will be mapped to the x-axis, y-axis (as well as color, shape, size, etc.). Geometries are the visual elements that will be used to represent the data, such as points, lines, bars, etc..\nAs discussed in the R lesson “Visual Summaries”, the aes() function is used to map variables to aesthetics and can be added to the ggplot() function or to the geom_*() function depending on whether the aesthetic is mapped to all geometries or to a specific geometry, respectively.\nTake a look at the following stages of the earlier plot in each of the tabs below.\n\nStages\n\nDataAestheticsGeometries\n\n\nThe data layer does not produce a plot but it is the foundation of the plot.\n\n# Data layer\nggplot(brown_fam_df)\n\n\n\n\n\n\n\n\n\n\nThe aesthetics layer does not produce a plot but it maps the variables to the aesthetics to be used in the plot.\n\n# Aesthetics layer\nggplot(brown_fam_df, aes(x = percent_passive))\n\n\n\n\n\n\n\n\n\n\nThe geometries layer produces the plot connecting the data and aesthetics layers in the particular way specified by the geometries, in this case a histogram.\n\n# Geometries layer\nggplot(brown_fam_df, aes(x = percent_passive)) +\n  geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\n\nChoosing the right plot\nJust as with tables, the type of summary we choose to communicate with a plot depends on the type of variables we are working with and the relationships between those variables.\nBelow I’ve included a few examples of plots that can be used to communicate different types of variables and relationships.\n\n\nSingle numeric variable\n\nHistogramDensity plot\n\n\n\n# Histogram\nggplot(brown_fam_df) +\n  geom_histogram(aes(x = percent_passive))\n\n\n\n\n\n\n\n\n\n\n\n# Density plot\nggplot(brown_fam_df) +\n  geom_density(aes(x = percent_passive))\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumeric and categorical variables\n\nDensity plotBoxplotViolin plot\n\n\n\n# Density plot\nggplot(brown_fam_df) +\n  geom_density(\n    aes(\n      x = percent_passive,\n      fill = lang_variety\n    ),\n    alpha = 0.5 # adds transparency\n  )\n\n\n\n\n\n\n\n\n\n\n\n# Boxplot\nggplot(brown_fam_df) +\n  geom_boxplot(\n    aes(\n      x = lang_variety,\n      y = percent_passive\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n# Violin plot\nggplot(brown_fam_df) +\n  geom_violin(\n    aes(\n      x = lang_variety,\n      y = percent_passive\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nTwo numeric variables\n\nScatterplotScatterplot with regression line\n\n\n\n# Scatterplot\nggplot(brown_fam_df) +\n  geom_point(\n    aes(\n      x = active_verbs,\n      y = passive_verbs\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\n# Scatterplot with regression line\nggplot(\n  brown_fam_df,\n  aes(\n    x = active_verbs,\n    y = passive_verbs\n  )\n) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nOther variable combinations\nIn these examples, we have only looked at the most common variable combinations for one and two variable plots. There are more sophisticated plots that can be used for other variable combinations using ggplot2. For now, we will leave these for another time."
  },
  {
    "objectID": "recipes/recipe-03/index.html#check-your-understanding",
    "href": "recipes/recipe-03/index.html#check-your-understanding",
    "title": "3. Descriptive assessment of datasets",
    "section": "Check your understanding",
    "text": "Check your understanding\n\nA factor is a character vector augmented to include information about the discrete values, or levels, of the vector. TRUEFALSE\nWhat is the difference between a frequency table and a contingency table? A frequency table is a cross-tabulation of two or more categorical variables.A contingency table is a cross-tabulation of two or more categorical variables.\nThe skimrdplyrggplot2knitr package is used to create formatted tables in R.\nTo add a geometry layer, such as geom_histogram(), to a ggplot object the |&gt; operator is used. TRUEFALSE\nTo visualize the relationship between two numeric variables, a histogramdensity plotboxplotviolin plotscatterplot is often used.\nWhen the aes() function is added to the ggplot() function, the aesthetic is mapped to all geometries. TRUEFALSE"
  },
  {
    "objectID": "recipes/recipe-03/index.html#lab-preparation",
    "href": "recipes/recipe-03/index.html#lab-preparation",
    "title": "3. Descriptive assessment of datasets",
    "section": "Lab preparation",
    "text": "Lab preparation\n\nBefore beginning Lab 3, learners should be comfortable with the skills and knowledge developed in the previous recipes and labs. In this lab, you will have a chance to use these skills and those introduced in this Recipe to provide a descriptive assessment of a dataset that includes statistics, tables, and plots using Quarto and R.\nThe additional skills and knowledge you will need to complete Lab 3 include:\n\nSummarizing data with skimr\nSummarizing data with dplyr\nCreating Quarto tables with knitr\nCreating Quarto plots with ggplot2"
  },
  {
    "objectID": "recipes/recipe-10/index.html",
    "href": "recipes/recipe-10/index.html",
    "title": "Recipe 10",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "guides/guide-05/index.html",
    "href": "guides/guide-05/index.html",
    "title": "Guide 05",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "guides/guide-03/index.html",
    "href": "guides/guide-03/index.html",
    "title": "Guide 03",
    "section": "",
    "text": "Hello."
  },
  {
    "objectID": "guides/index.html",
    "href": "guides/index.html",
    "title": "Guides",
    "section": "",
    "text": "1. Setting up an R environment\n\n\n\n\n\nIn this guide, we will explore options for setting up an R environment. We will discuss local, remote, and virtual environments. Each have their own advantages and shortcomings. The best option for you will depend on your needs and preferences. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuide 02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuide 03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuide 04\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGuide 05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]